{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4835839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn #neural network modules\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b548c14",
   "metadata": {},
   "source": [
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd715f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchaudio.datasets.LIBRISPEECH(\"./\", url=\"train-clean-100\", download=True)\n",
    "# test_dataset = torchaudio.datasets.LIBRISPEECH(\"./\", url=\"test-clean\", download=True)\n",
    "# dev_dataset = torchaudio.datasets.LIBRISPEECH(\"./\", url=\"dev-clean\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b16f17e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = []\n",
    "labels = []\n",
    "for i in range(10000):\n",
    "    sample = train_dataset.__getitem__(i)\n",
    "    waveform, _, label, _, _, _ = sample\n",
    "    specgram = T.MelSpectrogram(sample_rate=16000, win_length=400, hop_length=160, n_mels=80)(waveform)\n",
    "    waveforms.append(torch.squeeze(specgram))\n",
    "    labels.append(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dab67c0",
   "metadata": {},
   "source": [
    "print(waveforms[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d24038cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1595, 80])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "xtrain = []\n",
    "for i in range(len(waveforms)):\n",
    "    xtrain.append(waveforms[i].permute(1,0))\n",
    "print(xtrain[1].shape)\n",
    "padded_sequences = pad_sequence(xtrain, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52cbbdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([8000, 1930, 80])\n",
      "10000 8000\n"
     ]
    }
   ],
   "source": [
    "print(type(padded_sequences), padded_sequences[0:8000].shape)\n",
    "print(len(labels), len(labels[0:8000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3de24ac",
   "metadata": {},
   "source": [
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25090d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['sos'] + labels[0].lower().split() + ['eos']els"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca4238ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(labels):\n",
    "    for item in labels:\n",
    "        yield item.lower().strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76aedb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n"
     ]
    }
   ],
   "source": [
    "tokens = yield_tokens(labels)\n",
    "print(type(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77917053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "vocab = build_vocab_from_iterator(tokens,min_freq=1,specials=['<sos>', '<pad>'])\n",
    "vocab.append_token('<eos>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56516bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20376\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(vocab.__len__())\n",
    "print(vocab.__getitem__('<pad>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c19301",
   "metadata": {},
   "source": [
    "l = labels[0].lower().strip().split()\n",
    "print(l)\n",
    "print(vocab.lookup_indices(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "457eea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LibriDataset(Dataset):\n",
    "    def __init__(self, waveforms, labels, vocab):\n",
    "        self.waveforms = waveforms\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(waveforms)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        waveform = self.waveforms[index]\n",
    "#         print(waveform.shape)\n",
    "        label = self.labels[index]\n",
    "        numericalized_caption = []\n",
    "        numericalized_caption.append(self.vocab.__getitem__('<sos>'))\n",
    "        numericalized_caption+=self.vocab.lookup_indices(label.lower().strip().split())\n",
    "        numericalized_caption.append(self.vocab.__getitem__('<eos>'))\n",
    "\n",
    "        return waveform, torch.tensor(numericalized_caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4352dbe8",
   "metadata": {},
   "source": [
    "numericalized_caption = []\n",
    "numericalized_caption.append(vocab.__getitem__('<sos>'))\n",
    "numericalized_caption+=vocab.lookup_indices(labels[0].lower().strip().split())\n",
    "numericalized_caption.append(vocab.__getitem__('<eos>'))\n",
    "print(numericalized_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f20dd788",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCollate:\n",
    "    def __init__(self, pad_idx):\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    def __call__(self, batch):\n",
    "#         print(len(batch), print(batch[0]))\n",
    "#         for item in batch:\n",
    "#             print(item[0].shape)\n",
    "        waves = [item[0] for item in batch]\n",
    "#         print(waves[0].shape, waves[1].shape)\n",
    "        waves = torch.stack(waves, dim=0)\n",
    "#         print(type(waves), waves.shape)\n",
    "        targets = [item[1] for item in batch]\n",
    "        targets = pad_sequence(targets, batch_first=True, padding_value=self.pad_idx)\n",
    "\n",
    "        return waves, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d276ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LibriDataset(padded_sequences, labels, vocab)\n",
    "# train_loader = DataLoader(dataset=dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0baf8e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=64,\n",
    "        shuffle=True,\n",
    "        collate_fn=MyCollate(pad_idx=1))\n",
    "# print(len(labels[1].strip().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dda1324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conformer_encoder import ConformerBlock\n",
    "#conv subsampling\n",
    "class Conv2dSubampling(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional 2D subsampling (to 1/4 length)\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input image\n",
    "        out_channels (int): Number of channels produced by the convolution\n",
    "    Inputs: inputs\n",
    "        - **inputs** (batch, time, dim): Tensor containing sequence of inputs\n",
    "    Returns: outputs, output_lengths\n",
    "        - **outputs** (batch, time, dim): Tensor produced by the convolution\n",
    "        - **output_lengths** (batch): list of sequence output lengths\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int) -> None:\n",
    "        super(Conv2dSubampling, self).__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, input_lengths):\n",
    "        outputs = self.sequential(inputs.unsqueeze(1))\n",
    "#         print(outputs.size())\n",
    "        batch_size, channels, subsampled_lengths, sumsampled_dim = outputs.size()\n",
    "\n",
    "        outputs = outputs.permute(0, 2, 1, 3)\n",
    "        outputs = outputs.contiguous().view(batch_size, subsampled_lengths, channels * sumsampled_dim)\n",
    "\n",
    "        output_lengths = input_lengths >> 2\n",
    "        output_lengths -= 1\n",
    "\n",
    "        return outputs, output_lengths\n",
    "\n",
    "#Encoder\n",
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        self.conv2dss = Conv2dSubampling(1, 80)\n",
    "        self.linear = nn.Linear(731120, 768)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.conformer = ConformerBlock(dim = 1520, dim_head = 64, heads = 4, ff_mult = 2, conv_expansion_factor = 2,\n",
    "                                        conv_kernel_size = 31, attn_dropout = 0.2, ff_dropout = 0.1, conv_dropout = 0.2)\n",
    "\n",
    "    def forward(self, waves):\n",
    "        features = self.conv2dss(waves, torch.tensor([]))\n",
    "        features = self.conformer(features[0])\n",
    "        return self.dropout(self.relu(self.linear(features.reshape(features.shape[0], -1))))\n",
    "#Decoder\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size*2, hidden_size, num_layers)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, features, captions):\n",
    "        embeddings = self.dropout(self.embed(captions))\n",
    "        embeddings = torch.cat((features.unsqueeze(1).repeat(1, embeddings.shape[1], 1), embeddings), dim=2)\n",
    "        hiddens, _ = self.lstm(embeddings)\n",
    "        outputs = self.linear(hiddens)\n",
    "        return outputs\n",
    "#model    \n",
    "class ConformerEncDec(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers):\n",
    "        super(ConformerEncDec, self).__init__()\n",
    "        self.encoderCNN = EncoderCNN(embed_size)\n",
    "        self.decoderRNN = DecoderRNN(embed_size, hidden_size, vocab_size, num_layers)\n",
    "\n",
    "    def forward(self, images, captions):\n",
    "        features = self.encoderCNN(images)\n",
    "#         print(features.shape)\n",
    "        outputs = self.decoderRNN(features, captions)\n",
    "        return outputs\n",
    "\n",
    "    def predict_caption(self, waves, vocab, max_length=88):\n",
    "        result_caption = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = self.encoderCNN(waves).unsqueeze(0)\n",
    "            states = None\n",
    "\n",
    "            for _ in range(max_length):\n",
    "                hiddens, states = self.decoderRNN.lstm(x, states)\n",
    "                output = self.decoderRNN.linear(hiddens.squeeze(0))\n",
    "                predicted = output.argmax(2)\n",
    "                result_caption.append(predicted.item())\n",
    "                x = self.decoderRNN.embed(predicted).unsqueeze()\n",
    "\n",
    "                if vocab.__getitem__(predicted.item()) == \"<eos>\":\n",
    "                    break\n",
    "\n",
    "        return vocab.lookup_indices(result_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b027989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=\"my_model.pth.tar\"):\n",
    "    print(\"=> saving checkpoint\")\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "047075c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConformerEncDec(768, 320, vocab.__len__(), 1)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a5a94df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "0 6\n",
      "0 7\n",
      "0 8\n",
      "0 9\n",
      "0 10\n",
      "0 11\n",
      "0 12\n",
      "0 13\n",
      "0 14\n",
      "0 15\n",
      "0 16\n",
      "0 17\n",
      "0 18\n",
      "0 19\n",
      "0 20\n",
      "0 21\n",
      "0 22\n",
      "0 23\n",
      "0 24\n",
      "0 25\n",
      "0 26\n",
      "0 27\n",
      "0 28\n",
      "0 29\n",
      "0 30\n",
      "0 31\n",
      "0 32\n",
      "0 33\n",
      "0 34\n",
      "0 35\n",
      "0 36\n",
      "0 37\n",
      "0 38\n",
      "0 39\n",
      "0 40\n",
      "0 41\n",
      "0 42\n",
      "0 43\n",
      "0 44\n",
      "0 45\n",
      "0 46\n",
      "0 47\n",
      "0 48\n",
      "0 49\n",
      "0 50\n",
      "0 51\n",
      "0 52\n",
      "0 53\n",
      "0 54\n",
      "0 55\n",
      "0 56\n",
      "0 57\n",
      "0 58\n",
      "0 59\n",
      "0 60\n",
      "0 61\n",
      "0 62\n",
      "0 63\n",
      "0 64\n",
      "0 65\n",
      "0 66\n",
      "0 67\n",
      "0 68\n",
      "0 69\n",
      "0 70\n",
      "0 71\n",
      "0 72\n",
      "0 73\n",
      "0 74\n",
      "0 75\n",
      "0 76\n",
      "0 77\n",
      "0 78\n",
      "0 79\n",
      "0 80\n",
      "0 81\n",
      "0 82\n",
      "0 83\n",
      "0 84\n",
      "0 85\n",
      "0 86\n",
      "0 87\n",
      "0 88\n",
      "0 89\n",
      "0 90\n",
      "0 91\n",
      "0 92\n",
      "0 93\n",
      "0 94\n",
      "0 95\n",
      "0 96\n",
      "0 97\n",
      "0 98\n",
      "0 99\n",
      "0 100\n",
      "0 101\n",
      "0 102\n",
      "0 103\n",
      "0 104\n",
      "0 105\n",
      "0 106\n",
      "0 107\n",
      "0 108\n",
      "0 109\n",
      "0 110\n",
      "0 111\n",
      "0 112\n",
      "0 113\n",
      "0 114\n",
      "0 115\n",
      "0 116\n",
      "0 117\n",
      "0 118\n",
      "0 119\n",
      "0 120\n",
      "0 121\n",
      "0 122\n",
      "0 123\n",
      "0 124\n",
      "0 125\n",
      "0 126\n",
      "0 127\n",
      "0 128\n",
      "0 129\n",
      "0 130\n",
      "0 131\n",
      "0 132\n",
      "0 133\n",
      "0 134\n",
      "0 135\n",
      "0 136\n",
      "0 137\n",
      "0 138\n",
      "0 139\n",
      "0 140\n",
      "0 141\n",
      "0 142\n",
      "0 143\n",
      "0 144\n",
      "0 145\n",
      "0 146\n",
      "0 147\n",
      "0 148\n",
      "0 149\n",
      "0 150\n",
      "0 151\n",
      "0 152\n",
      "0 153\n",
      "0 154\n",
      "0 155\n",
      "0 156\n",
      "epoch 1\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "1 8\n",
      "1 9\n",
      "1 10\n",
      "1 11\n",
      "1 12\n",
      "1 13\n",
      "1 14\n",
      "1 15\n",
      "1 16\n",
      "1 17\n",
      "1 18\n",
      "1 19\n",
      "1 20\n",
      "1 21\n",
      "1 22\n",
      "1 23\n",
      "1 24\n",
      "1 25\n",
      "1 26\n",
      "1 27\n",
      "1 28\n",
      "1 29\n",
      "1 30\n",
      "1 31\n",
      "1 32\n",
      "1 33\n",
      "1 34\n",
      "1 35\n",
      "1 36\n",
      "1 37\n",
      "1 38\n",
      "1 39\n",
      "1 40\n",
      "1 41\n",
      "1 42\n",
      "1 43\n",
      "1 44\n",
      "1 45\n",
      "1 46\n",
      "1 47\n",
      "1 48\n",
      "1 49\n",
      "1 50\n",
      "1 51\n",
      "1 52\n",
      "1 53\n",
      "1 54\n",
      "1 55\n",
      "1 56\n",
      "1 57\n",
      "1 58\n",
      "1 59\n",
      "1 60\n",
      "1 61\n",
      "1 62\n",
      "1 63\n",
      "1 64\n",
      "1 65\n",
      "1 66\n",
      "1 67\n",
      "1 68\n",
      "1 69\n",
      "1 70\n",
      "1 71\n",
      "1 72\n",
      "1 73\n",
      "1 74\n",
      "1 75\n",
      "1 76\n",
      "1 77\n",
      "1 78\n",
      "1 79\n",
      "1 80\n",
      "1 81\n",
      "1 82\n",
      "1 83\n",
      "1 84\n",
      "1 85\n",
      "1 86\n",
      "1 87\n",
      "1 88\n",
      "1 89\n",
      "1 90\n",
      "1 91\n",
      "1 92\n",
      "1 93\n",
      "1 94\n",
      "1 95\n",
      "1 96\n",
      "1 97\n",
      "1 98\n",
      "1 99\n",
      "1 100\n",
      "1 101\n",
      "1 102\n",
      "1 103\n",
      "1 104\n",
      "1 105\n",
      "1 106\n",
      "1 107\n",
      "1 108\n",
      "1 109\n",
      "1 110\n",
      "1 111\n",
      "1 112\n",
      "1 113\n",
      "1 114\n",
      "1 115\n",
      "1 116\n",
      "1 117\n",
      "1 118\n",
      "1 119\n",
      "1 120\n",
      "1 121\n",
      "1 122\n",
      "1 123\n",
      "1 124\n",
      "1 125\n",
      "1 126\n",
      "1 127\n",
      "1 128\n",
      "1 129\n",
      "1 130\n",
      "1 131\n",
      "1 132\n",
      "1 133\n",
      "1 134\n",
      "1 135\n",
      "1 136\n",
      "1 137\n",
      "1 138\n",
      "1 139\n",
      "1 140\n",
      "1 141\n",
      "1 142\n",
      "1 143\n",
      "1 144\n",
      "1 145\n",
      "1 146\n",
      "1 147\n",
      "1 148\n",
      "1 149\n",
      "1 150\n",
      "1 151\n",
      "1 152\n",
      "1 153\n",
      "1 154\n",
      "1 155\n",
      "1 156\n",
      "epoch 2\n",
      "=> saving checkpoint\n",
      "2 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-33f30eb1000d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ap/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-6d3154086c12>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, captions)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoderCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;31m#         print(features.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ap/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-6d3154086c12>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, waves)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwaves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2dss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m#Decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ap/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/KC-Study/sem3/Project1/conformer_encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ap/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/KC-Study/sem3/Project1/conformer_encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mPreNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    losses = []\n",
    "    print(\"epoch\", epoch)\n",
    "    if epoch==2:\n",
    "        checkpoint = {'state_dict':model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "        save_checkpoint(checkpoint)\n",
    "    for batch_idx, (data, targets) in enumerate(loader):\n",
    "        print(epoch, batch_idx)\n",
    "        o = model(data, targets)\n",
    "        loss = criterion(o.reshape(-1, o.shape[2]), targets.reshape(-1))\n",
    "        losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(loss)\n",
    "        optimizer.step()\n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "#     print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "855470cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.823648811145953 tensor(6.7516, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(mean_loss, loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
